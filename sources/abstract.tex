\begin{abstract}
The primary objective of this work is to provide a thorough review and enhancement of recent advancements in the field of automatically transforming performance MIDI recordings into musical scores, which is a part of a more general task: \emph{Automatic Music Transcription}, that is extracting symbolic representations of music from raw audio signal.

The work focuses primarily on extending the methodology proposed in the paper titled \emph{Performance MIDI-to-Score Conversion by Neural Beat Tracking} \cite{Liu2022}. In this paper work, the authors introduced a novel approach that amalgamates Neural Beat Tracking techniques with Convolutional Recurrent Neural Networks to facilitate the conversion of MIDI recordings, specifically piano performances, into musical scores. 

The scope of this study includes a comprehensive examination of the aforementioned techniques, along with augmentations of these methods, involving incorporating additional musical elements, particularly note dynamics. As a consequence, the work extends the widely-used score evaluation metric, MV2H (\emph{Multi-pitch detection, Voice separation, Metrical alignment, Note Value detection and Harmonic Analysis}) \cite{McLeod2018}, with \emph{Dynamic detection}.
\end{abstract}
