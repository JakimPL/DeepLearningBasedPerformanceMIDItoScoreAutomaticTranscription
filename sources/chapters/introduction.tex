\chapter*{Introduction}

\addcontentsline{toc}{chapter}{Introduction}

The aim of this thesis is to explore the topic of automatic transcription of performance MIDI into musical scores. The discussion is preceded by an introduction to the necessary concepts and theoretical frameworks. The problem is placed within the broader context of \emph{Automatic Music Transcription}, which is itself a subset of the broader domain of \emph{Music Information Retrieval}. A brief history of the field is provided, along with an overview of the challenges and difficulties associated with automating music transcription.

We also delve into how the quality of transcriptions can be measured and the challenges inherent in their evaluation. Three sets of metrics are presented, each representing a distinct approach to assessing transcription quality: MUSTER, MV2H, and \emph{Score Similarity}.

The main thesis focuses on the state-of-the-art model for MIDI transcription, \emph{Performance MIDI-to-Score Conversion by Neural Beat Tracking} \cite{Liu2022}. This model was the first to successfully utilize machine learning methods for (almost) complete MIDI to score transcription. We provide a detailed discussion of the model’s architecture, performance results, and observed behaviors.

Using custom explainable machine learning tools, we analyze the model’s undesired behaviors in depth and introduce methods to better understand its individual decisions. We also highlight several common transcription problems generated by the model. Insights gained from this analysis were used to improve the model’s robustness to specific transformations. The results of this investigation are presented in the experimental section.

Beyond the above, we conducted experiments comparing the base model with two other promising architectures: \emph{Transformers} and \emph{Temporal Convolutional Networks}. Moreover, we extended the base model by incorporating an additional component for handling dynamics. Additionally, we proposed a method to evaluate the quality of dynamics transcription as an extension of the MV2H metric while maintaining its foundational principles.

At the end of the thesis, we summarize the entire work. We describe potential improvements paths.

This thesis aims to be accessible without requiring prior knowledge of advanced music theory. While we have strived to clarify musical concepts as much as possible, it is beyond the scope of this work to explain all of used musical terms. Readers interested in a deeper understanding of musical terminology are encouraged to refer to \cite{Read1969}, which offers a detailed explanation of the musical elements discussed.

All models were trained on the \emph{Entropy} computing cluster, provided by the \emph{Faculty of Mathematics, Informatics, and Mechanics} at the \emph{University of Warsaw}.

I would also like to acknowledge the assistance of \emph{ChatGPT} in helping me translate some of my clumsy sentences into a more human-readable format.